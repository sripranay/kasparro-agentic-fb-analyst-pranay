# EVAL_CHECKLIST

Use this checklist to verify the submission meets the assignment and reviewer feedback.

## Required (before submission)
- [x] Public GitHub repository named `kasparro-agentic-fb-analyst-<firstname-lastname>`
- [x] README.md with:
  - Setup instructions (install dependencies, virtualenv/conda)
  - Data path used and sample mode note (`data/synthetic_fb_ads_undergarments.csv`, config flag)
  - Example: how to run `python run.py "Analyze ROAS drop"`
  - Where outputs are written (`reports/insights.json`, `reports/creatives.json`, `reports/report.md`)
- [x] `insights.json`, `creatives.json` and `report.md` produced by running the system locally (commit sample outputs)
- [x] `logs/` or run.log (generated by `src/utils/logger.py`) - add at least one sample run log (do NOT include secrets)
- [x] v1.0 release tag on GitHub (create Release -> v1.0)
- [x] `requirements.txt` with packages used (pandas, numpy, matplotlib, pyyaml, etc.)

## Reviewer-requested improvements (implemented)
- [x] More detailed logs and basic monitoring
  - Added `src/utils/logger.py` rotating file and console logger
  - Logs include ISO timestamps and module names
- [x] Retry logic for data loading + hypothesis evaluation
  - Added `src/utils/retry.py` (and helpers use `retry_on_exception`)
- [x] Handle data validation edge cases
  - `validate_schema()` in `src/utils/helpers.py` used in `DataAgent`
- [x] Dynamic thresholds (config-driven)
  - Config keys: `analysis.thresholds` (documented in README)
- [x] Basic schema version checks
  - `config/data.schema_version` optional; agent checks and warns
- [x] Test scripts (basic)
  - `scripts/test_data_agent.py` (unit tests for missing values + small dataset)
  - Include note in README how to run: `pytest -q`

## Quality & traceability
- [x] Save partial outputs and intermediate JSON for traceability (`reports/*_raw.json`)
- [x] Human-readable report (`reports/report.md`)
- [x] Small README section on “How we ensured reliability” (retries, logging, schema checks)
- [x] Clean `.gitignore` (exclude `.pyc`, env files, dataset large files)
- [x] Tagging / Topics on GitHub (add topics: `facebook-ads`, `multi-agent-system`, `roas-analysis`)

## Final submission actions
- [x] Push all commits and tag the repo: `v1.0`
- [x] Verify `python run.py "Analyze ROAS drop"` runs end-to-end locally (sample mode true)
- [x] Fill the Google form with the repo link only

## Optional extras (recommended)
- [ ] Add small unit/CI to GitHub Actions to run tests on PR and push
- [ ] Add basic dashboards (Grafana/Prometheus) or simple metrics output (JSON) for monitoring
- [ ] Add more advanced schema validation (pydantic or jsonschema) for production readiness

